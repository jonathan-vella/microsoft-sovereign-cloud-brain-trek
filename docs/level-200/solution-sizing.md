---
layout: default
title: Solution Sizing & Planning
parent: Level 200 - Intermediate
nav_order: 4
---

# Solution Sizing & Planning

> **ðŸ“Š Visual Reference: Asset 33 - Solution Sizing Framework**  
> *Placeholder - See docs/assets/images/README.md#asset-33*  
> Interactive sizing process showing input variables (workload type, user count, data volume, growth), calculation layers (compute/storage/network sizing), decision points for HA/redundancy, and output configurations with cost estimates and confidence ranges.

## Overview

Solution sizing translates customer requirements into specific hardware configurations, software components, and deployment architectures. This page covers workload assessment, sizing calculators, capacity planning, and validation techniques.

---

## Solution Sizing Methodology

### Three-Phase Sizing Process

```
PHASE 1: REQUIREMENTS EXTRACTION (1-2 weeks)
â”œâ”€ Workload characterization
â”œâ”€ Performance requirements
â”œâ”€ Scale and growth projections
â””â”€ Operational constraints

PHASE 2: CAPACITY CALCULATION (1 week)
â”œâ”€ CPU/Memory sizing
â”œâ”€ Storage sizing
â”œâ”€ Network requirements
â””â”€ GPU/accelerator needs

PHASE 3: VALIDATION & OPTIMIZATION (1 week)
â”œâ”€ Benchmark against requirements
â”œâ”€ Cost optimization analysis
â”œâ”€ Risk mitigation planning
â””â”€ Final recommendation & presentation
```

---

## Workload Classification & Profiling

### Workload Categories

```
CATEGORY 1: Inference (AI/ML prediction)
â”œâ”€ Characteristics:
â”‚  â”œâ”€ High throughput (100-10000 QPS)
â”‚  â”œâ”€ Low latency requirement (<500ms)
â”‚  â”œâ”€ GPU-intensive
â”‚  â””â”€ Stateless operations
â”œâ”€ Sizing Focus:
â”‚  â”œâ”€ GPU count and memory
â”‚  â”œâ”€ Batch processing capability
â”‚  â””â”€ Network throughput

CATEGORY 2: Analytics/Reporting
â”œâ”€ Characteristics:
â”‚  â”œâ”€ Batch processing
â”‚  â”œâ”€ High data volume (TB-PB)
â”‚  â”œâ”€ Flexible timing
â”‚  â””â”€ CPU-intensive
â”œâ”€ Sizing Focus:
â”‚  â”œâ”€ Storage capacity
â”‚  â”œâ”€ CPU cores
â”‚  â””â”€ Network bandwidth

CATEGORY 3: Transactional Database
â”œâ”€ Characteristics:
â”‚  â”œâ”€ Consistent throughput (1000-100K TPS)
â”‚  â”œâ”€ Low latency (<10ms)
â”‚  â”œâ”€ High availability
â”‚  â””â”€ ACID compliance
â”œâ”€ Sizing Focus:
â”‚  â”œâ”€ Memory (cache efficiency)
â”‚  â”œâ”€ IOPS (disk speed)
â”‚  â””â”€ Network latency

CATEGORY 4: Vector Search (RAG)
â”œâ”€ Characteristics:
â”‚  â”œâ”€ Moderate throughput (100-10000 QPS)
â”‚  â”œâ”€ Similarity search
â”‚  â”œâ”€ Memory-resident indexes
â”‚  â””â”€ GPU-optional
â”œâ”€ Sizing Focus:
â”‚  â”œâ”€ Memory (index size)
â”‚  â”œâ”€ Network I/O
â”‚  â””â”€ CPU cores for search
```

### Workload Profile Template

```
WORKLOAD NAME: [Name]
WORKLOAD TYPE: [Classification]
BUSINESS CONTEXT: [Why this matters]

SCALE CHARACTERISTICS:
â”œâ”€ Concurrent Users: [Number]
â”œâ”€ Queries/Transactions per Second:
â”‚  â”œâ”€ Average: [X QPS]
â”‚  â”œâ”€ Peak: [Y QPS, Z% of time]
â”‚  â””â”€ 99th percentile: [W QPS]
â”œâ”€ Data Volume:
â”‚  â”œâ”€ Current: [Size]
â”‚  â”œâ”€ Year 1: [Size]
â”‚  â”œâ”€ Year 3: [Size]
â”‚  â””â”€ Growth Rate: [% per year]

PERFORMANCE REQUIREMENTS:
â”œâ”€ Latency:
â”‚  â”œâ”€ p50: [ms]
â”‚  â”œâ”€ p95: [ms]
â”‚  â””â”€ p99: [ms]
â”œâ”€ Throughput: [Transactions/sec]
â”œâ”€ Availability: [SLA %]
â””â”€ Error Rate: [Target %]

INFRASTRUCTURE CONSTRAINTS:
â”œâ”€ Hardware Available: [Description]
â”œâ”€ Power Budget: [kW]
â”œâ”€ Network Bandwidth: [Mbps]
â”œâ”€ Physical Space: [sq ft]
â””â”€ Environmental: [Temperature, humidity, etc.]

OPERATIONAL CONSTRAINTS:
â”œâ”€ Maintenance Windows: [Frequency]
â”œâ”€ Failover Requirements: [RPO/RTO]
â”œâ”€ Compliance Audits: [Frequency]
â””â”€ Support Model: [24/7, business hours, etc.]
```

---

## Hardware Sizing Calculators

### CPU Sizing Calculator

```
STEP 1: Estimate CPU Requirements
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Per-Query CPU Time: [ms]
  (from benchmarking or vendor data)

Queries per Second (peak): [QPS]

Cores Needed = (QPS Ã— CPU_time_ms Ã— num_threads) / (core_time_per_sec Ã— efficiency)

Example:
  - 500 QPS peak
  - 50ms CPU time per query
  - 4 threads per query
  - 85% CPU efficiency
  
  Cores = (500 Ã— 50 Ã— 4) / (1000 Ã— 0.85) = 117 cores needed
  
  â†’ Recommend: 4 nodes Ã— 32 cores = 128 cores
  â†’ Provides 9% headroom

STEP 2: Add Overhead for System Services
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - Operating system: 15% of cores
  - Monitoring/logging: 10% of cores
  - Cache/buffers: 5% of cores
  - Headroom for peaks: 10% of cores
  
  Total Overhead: ~40% of cores
  
  Adjusted cores needed = 117 / 0.6 = 195 cores

STEP 3: Select Hardware
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - Dual-socket servers, 32 cores each = 64 cores/server
  - 195 / 64 = 3.05 â†’ Recommend 4 servers
  
RESULT: 4 servers with dual 32-core processors
```

### Memory Sizing Calculator

```
STEP 1: Identify Memory Components
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Working Set Size:
  - Active data in use: [GB]
  - Example: LLM model (7B params in INT4) = 2GB

Cache Layers:
  - Application cache: [GB]
  - Database buffer pool: [GB]
  - OS page cache: [GB]
  - Total cache: [GB]

Index Structures:
  - Vector index (HNSW for 1M vecs): 2KB per vector = 2GB
  - B-tree indexes: varies
  - Hash tables: varies
  - Total: [GB]

Temporary Allocations:
  - Query processing: [GB]
  - Sort buffers: [GB]
  - Join buffers: [GB]
  - Total: [GB]

STEP 2: Calculate Total Memory
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total = Working Set + Cache + Indexes + Temp + Headroom (25%)

Example:
  - Working Set (LLM): 2GB
  - Cache: 64GB
  - Indexes (1M vectors): 2GB
  - Temp buffers: 10GB
  - Headroom (25%): 19.5GB
  
  Total: ~98GB â†’ Round to 128GB per server

STEP 3: Memory Layout per Server
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
With 384GB server (enterprise hardware):
  - LLM model: 2GB (40% GPU VRAM, 60% host)
  - Vector index: 2GB
  - Buffer pool: 256GB
  - OS + overhead: 124GB
  
  Utilization: ~340/384 = 88.5%
```

### GPU Sizing Calculator

```
STEP 1: Assess GPU Requirements
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model Requirements:
  - Llama 2 7B in INT4: ~2GB VRAM
  - Mistral 7B in INT8: ~8GB VRAM
  - Llama 2 13B in INT8: ~14GB VRAM

Inference Requirements:
  - QPS: 500 peak
  - Model latency: 200ms per query
  - Batch size: 4 (256ms latency, 2000 QPS capacity)
  
GPU Memory Needed:
  - Model: 2GB (INT4 quantized)
  - Batch buffers: 1GB (4x batch size)
  - Embeddings: 0.5GB
  - Total per GPU: 3.5GB
  
  Utilization per GPU: 3.5GB / 16GB = 22%
  
STEP 2: Calculate GPU Count
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
With Batch Processing:
  - Batching 4 queries: 2000 QPS theoretical
  - Need 500 QPS: 1 GPU sufficient mathematically
  - Add redundancy: 2 GPUs
  - Add failure headroom: 3 GPUs
  
  â†’ 3x T4 GPUs (16GB each)

STEP 3: Validate Load Distribution
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - 500 QPS across 3 GPUs = 167 QPS per GPU
  - Batch size 4 = 42 batches/second per GPU
  - Processing time: 200ms + overhead = 250ms per batch
  - Capacity: 1000/250ms Ã— 4 = 16,000 QPS per GPU âœ“
  
  Result: 3 GPUs provides 10x headroom

STEP 4: CPU Support for GPU Operations
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - 1 CPU core per GPU for host processing
  - 2-4 CPU cores for driver and utilities
  - With 3 GPUs: allocate 6 cores minimum
```

### Storage Sizing Calculator

```
STEP 1: Categorize Storage Needs
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Hot Storage (SSD, <10ms latency):
  - Active vector indexes: 2GB
  - LLM model cache: 2GB
  - Database working set: 50GB
  - Total hot: 54GB

Warm Storage (NVMe/SSD, <100ms latency):
  - Full embeddings backup: 6GB
  - Model variants: 10GB
  - Query logs (1 week): 100GB
  - Total warm: 116GB

Cold Storage (HDD/Archive, <1s latency):
  - Historical query logs: 500GB
  - Data backups: 200GB
  - Total cold: 700GB

STEP 2: Calculate Total with Replication
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Replication Factor: 2x (high availability)

  - Hot storage: 54GB Ã— 2 = 108GB SSD
  - Warm storage: 116GB Ã— 2 = 232GB NVMe
  - Cold storage: 700GB Ã— 2 = 1.4TB HDD
  
  Total: ~1.8TB raw storage

STEP 3: Add Growth Buffer (30% per year)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Year 1: 1.8TB
Year 2: 1.8TB Ã— 1.3 = 2.3TB
Year 3: 2.3TB Ã— 1.3 = 3TB

Recommendation: Procure 3TB usable with tiering
```

### Network Sizing Calculator

```
STEP 1: Calculate Bandwidth Requirements
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ingress (Data flowing in):
  - Query traffic: 500 QPS Ã— 2KB query = 1 MB/sec
  - Data ingestion: 100 MB/hour
  - Replication sync: 50 Mbps (peak)
  - Total ingress: ~50 Mbps average, 150 Mbps peak

Egress (Data flowing out):
  - Query responses: 500 QPS Ã— 5KB response = 2.5 MB/sec
  - Replication egress: 50 Mbps
  - Monitoring/logging: 20 Mbps
  - Total egress: ~70 Mbps average, 200 Mbps peak

Cluster Internal:
  - Node-to-node replication: 50 Mbps
  - Storage access: 100 Mbps
  - Monitoring: 10 Mbps
  - Total internal: ~160 Mbps average, 400 Mbps peak

STEP 2: Size Network Interfaces
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
External-facing (to users/services):
  - 200 Mbps peak required
  - Recommend: Dual 10Gbps uplinks (20 Gbps total)
  - Utilization: <1%

Cluster-internal (node-to-node):
  - 400 Mbps peak required
  - Recommend: 25Gbps fabric interconnect
  - Utilization: <2%

Per-server network:
  - External: 10Gbps NIC (1000x peak requirement)
  - Internal: 25Gbps interconnect

STEP 3: Network Services Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Balancer:
  - Capacity: 20 Gbps minimum
  - Connection tracking: 100K sessions
  - NAT throughput: 5 Gbps

Firewall:
  - Stateful inspection: 20 Gbps minimum
  - Connection limit: 1M concurrent

Switch Fabric:
  - Non-blocking: Full bandwidth between all ports
  - Redundancy: Dual switches, active-active

Backup Network:
  - Dedicated for replication
  - 25Gbps capacity
```

---

## Capacity Planning & Growth

### Growth Projection Framework

```
CURRENT STATE (Year 0):
â”œâ”€ Users: 50 concurrent
â”œâ”€ Queries: 100K/day (1.15 QPS avg)
â”œâ”€ Data: 100K vectors (200MB)
â””â”€ Hardware: 2 nodes + 1 GPU

YEAR 1 PROJECTION (30% growth):
â”œâ”€ Users: 65 concurrent
â”œâ”€ Queries: 130K/day (1.5 QPS avg)
â”œâ”€ Data: 130K vectors (260MB)
â””â”€ Action: Monitor, no changes needed

YEAR 2 PROJECTION (30% growth):
â”œâ”€ Users: 85 concurrent
â”œâ”€ Queries: 169K/day (2 QPS avg)
â”œâ”€ Data: 169K vectors (338MB)
â””â”€ Action: Prepare for expansion

YEAR 3 PROJECTION (30% growth):
â”œâ”€ Users: 110 concurrent
â”œâ”€ Queries: 220K/day (2.5 QPS avg)
â”œâ”€ Data: 220K vectors (440MB)
â””â”€ Action: Add additional replicas

YEAR 5 PROJECTION (Conservative, slowing growth):
â”œâ”€ Users: 200 concurrent
â”œâ”€ Queries: 500K/day (5.8 QPS avg)
â”œâ”€ Data: 500K vectors (1GB)
â””â”€ Action: Consider multi-cluster sharding
```

### Capacity Monitoring & Triggers

```
METRIC: CPU Utilization
â”œâ”€ Yellow (75%): Plan upgrade timeline
â”œâ”€ Red (90%): Implement optimization or upgrade
â”œâ”€ Critical (95%): Escalate immediately

METRIC: Memory Utilization
â”œâ”€ Yellow (80%): Monitor swap activity
â”œâ”€ Red (90%): Plan hardware upgrade
â”œâ”€ Critical (95%): Implement emergency measures

METRIC: Storage I/O (IOPS)
â”œâ”€ Yellow (70% of limit): Monitor workload patterns
â”œâ”€ Red (85% of limit): Add storage or optimize queries
â”œâ”€ Critical (95% of limit): Escalate, may impact SLA

METRIC: Network Bandwidth
â”œâ”€ Yellow (60% of capacity): Monitor usage patterns
â”œâ”€ Red (80% of capacity): Consider network upgrade
â”œâ”€ Critical (95% of capacity): Escalate immediately

TRIGGER ACTIONS:
â”œâ”€ Yellow State: Send notification to ops team
â”œâ”€ Red State: Create upgrade planning ticket
â”œâ”€ Critical State: Execute emergency response playbook
```

---

## Sizing Validation Techniques

### Benchmark-Based Validation

```
STEP 1: Identify Reference Workload
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Similar customer workload:
  - 500 QPS peak load
  - 1M vector embeddings
  - Llama 2 7B model

Benchmark Results from Reference:
  - 3x T4 GPUs: 2000 QPS capacity
  - 4x CPU nodes: 4000 req/sec processing
  - Total storage: 2TB with HA

STEP 2: Scale to Your Requirements
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Your Peak Load: 500 QPS
Reference Benchmark: 2000 QPS capacity
Scaling Factor: 500 / 2000 = 0.25x

Your Hardware Needs:
  - GPUs: 3 Ã— 0.25 = 0.75 â†’ round up to 1 GPU
  - But add redundancy: use 2 GPUs
  - CPU nodes: scale similarly
  - Storage: scale proportionally

STEP 3: Validation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Performance Model Prediction:
  - 2 T4 GPUs: 1333 QPS capacity
  - Expected latency: 180ms p95
  - Storage needs: 500GB

Customer Requirement Alignment:
  - Required QPS: 500 âœ“ (67% headroom)
  - Required latency: <200ms âœ“ (meets p95)
  - Required storage: <500GB âœ“ (meets requirement)

VERDICT: Sizing meets requirements with 50% headroom
```

### Load Testing Validation

```
PHASE 1: Baseline Testing (Week 1)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Deploy proposed hardware
Run representative workload:
  - Ramp up from 10% to 100% of expected load
  - Measure latency, throughput, CPU, memory
  - Collect performance data for 6 hours

Expected Results:
  - p50 latency: <100ms
  - p95 latency: <200ms
  - CPU utilization: <70%
  - Memory utilization: <80%

PHASE 2: Peak Load Testing (Week 2)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Run spike tests to peak expected load:
  - Instantaneous ramp to 100% load
  - Sustain for 30 minutes
  - Measure recovery time

Expected Results:
  - Latency degradation <20%
  - No request timeouts
  - Recovery to baseline within 2 minutes

PHASE 3: Stress Testing (Week 3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Run 150% of peak expected load:
  - Identify breaking point
  - Test failover and recovery
  - Verify graceful degradation

Expected Results:
  - System remains responsive
  - Graceful throttling below peak at 150%
  - No data loss during failover

PASS/FAIL CRITERIA:
âœ“ PASS if all phases meet expected results
âœ— FAIL if any metric significantly misses
  â†’ If failed: Re-size and re-test
```

---

## Sizing Output Document

### Executive Summary Section

```
PROPOSED SOLUTION SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Deployment Model: [Single/Multi-region Hub-Spoke, etc.]
Hardware: [Component list]
Software: [Platform and tools]
Estimated Cost: [$ figure]
Implementation Timeline: [Weeks/months]

CAPACITY PROFILE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Peak Throughput: [X QPS or TPS]
Concurrent Users: [N users]
Data Volume: [Size]
Storage Capacity: [Size]
Network Bandwidth: [Mbps]

PERFORMANCE TARGETS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Latency p95: [ms]
Availability: [SLA %]
Throughput: [ops/sec]
Cost per Transaction: [$]

VALIDATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Benchmark Match: [Yes/No]
Load Test Results: [Pass/Fail]
Risk Assessment: [Low/Medium/High]
Confidence Level: [%]
```

---

## Related Topics

- **Main Page:** [Pre-Sales & Solution Design](./presales-solution-design.md)
- **Discovery:** [Customer Discovery](./customer-discovery.md)
- **Cost Analysis:** [Cost Estimation & TCO](./cost-estimation.md)
- **Proposals:** [Proposal Development](./proposal-development.md)
- **Quiz:** [Pre-Sales Quiz](./presales-quiz.md)

---

*Last Updated: October 21, 2025*
